code_long = [
    ["import torch\nimport transformers", "Import Statements"],
    ["DOWNLOAD_URL = \"https://github.com/unitaryai/detoxify/releases/download/\"\nMODEL_URLS = {\n    \"original\": DOWNLOAD_URL + \"v0.1-alpha/toxic_original-c1212f89.ckpt\",\n    \"unbiased\": DOWNLOAD_URL + \"v0.3-alpha/toxic_debiased-c7548aa0.ckpt\",\n    \"multilingual\": DOWNLOAD_URL + \"v0.4-alpha/multilingual_debiased-0b549669.ckpt\",\n    \"original-small\": DOWNLOAD_URL + \"v0.1.2/original-albert-0e1d6498.ckpt\",\n    \"unbiased-small\": DOWNLOAD_URL + \"v0.1.2/unbiased-albert-c8519128.ckpt\",\n}\n\nPRETRAINED_MODEL = None", "Constants and Shorthand Definition"],
    ["def get_model_and_tokenizer(\n    model_type, model_name, tokenizer_name, num_classes, state_dict, huggingface_config_path=None\n):", "Function Definition and Doc string"],
    ["model_class = getattr(transformers, model_name)\n    try:\n        # old transformer versions\n        model = model_class.from_pretrained(\n            pretrained_model_name_or_path=None,\n            config=huggingface_config_path or model_type,\n            num_labels=num_classes,\n            state_dict=state_dict,\n            local_files_only=huggingface_config_path is not None,\n        )\n    except Exception:\n        # new transformer versions\n        model = model_class.from_pretrained(\n            pretrained_model_name_or_path=model_type,\n            config=huggingface_config_path or model_type,\n            num_labels=num_classes,\n            state_dict=state_dict,\n            local_files_only=huggingface_config_path is not None,\n        )\n\n    tokenizer = getattr(transformers, tokenizer_name).from_pretrained(\n        huggingface_config_path or model_type,\n        local_files_only=huggingface_config_path is not None,\n        # TODO: may be needed to let it work with Kaggle competition\n        # model_max_length=512,\n    )\n\n    return model, tokenizer", "Function Logic"],
    ["def load_checkpoint(model_type=\"original\", checkpoint=None, device=\"cpu\", huggingface_config_path=None):", "Function Definition and Doc string"],
    ["if checkpoint is None:\n        checkpoint_path = MODEL_URLS[model_type]\n        loaded = torch.hub.load_state_dict_from_url(checkpoint_path, map_location=device)\n    else:\n        loaded = torch.load(checkpoint, map_location=device)\n        if \"config\" not in loaded or \"state_dict\" not in loaded:\n            raise ValueError(\n                \"Checkpoint needs to contain the config it was trained \\\n                    with as well as the state dict\"\n            )\n    class_names = loaded[\"config\"][\"dataset\"][\"args\"][\"classes\"]\n    # standardise class names between models\n    change_names = {\n        \"toxic\": \"toxicity\",\n        \"identity_hate\": \"identity_attack\",\n        \"severe_toxic\": \"severe_toxicity\",\n    }\n    class_names = [change_names.get(cl, cl) for cl in class_names]\n    model, tokenizer = get_model_and_tokenizer(\n        **loaded[\"config\"][\"arch\"][\"args\"],\n        state_dict=loaded[\"state_dict\"],\n        huggingface_config_path=huggingface_config_path,\n    )\n\n    return model, tokenizer, class_names", "Function Logic"],
    ["class Detoxify:\n"\"\"\"Detoxify\n    Easily predict if a comment or list of comments is toxic.\n    Can initialize 5 different model types from model type or checkpoint path:\n        - original:\n            model trained on data from the Jigsaw Toxic Comment\n            Classification Challenge\n        - unbiased:\n            model trained on data from the Jigsaw Unintended Bias in\n            Toxicity Classification Challenge\n        - multilingual:\n            model trained on data from the Jigsaw Multilingual\n            Toxic Comment Classification Challenge\n        - original-small:\n            lightweight version of the original model\n        - unbiased-small:\n            lightweight version of the unbiased model\n    Args:\n        model_type(str): model type to be loaded, can be either original,\n                         unbiased or multilingual\n        checkpoint(str): checkpoint path, defaults to None\n        device(str or torch.device): accepts any torch.device input or\n                                     torch.device object, defaults to cpu\n        huggingface_config_path: path to HF config and tokenizer files needed for offline model loading\n    Returns:\n        results(dict): dictionary of output scores for each class\n    \"\"\"", "Class Definition and Doc string"],
    ["def __init__(self, model_type=\"original\", checkpoint=PRETRAINED_MODEL, device=\"cpu\", huggingface_config_path=None):", "Function Definition and Doc string"],
    ["super().__init__()\n        self.model, self.tokenizer, self.class_names = load_checkpoint(\n            model_type=model_type,\n            checkpoint=checkpoint,\n            device=device,\n            huggingface_config_path=huggingface_config_path,\n        )\n        self.device = device\n        self.model.to(self.device)", "Function Logic"],
    ["@torch.no_grad()\n    def predict(self, text):", "Function Definition and Doc string"],
    ["self.model.eval()\n        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(self.model.device)\n        out = self.model(**inputs)[0]\n        scores = torch.sigmoid(out).cpu().detach().numpy()\n        results = {}\n        for i, cla in enumerate(self.class_names):\n            results[cla] = (\n                scores[0][i] if isinstance(text, str) else [scores[ex_i][i].tolist() for ex_i in range(len(scores))]\n            )\n        return results", "Function Logic"],
    ["def toxic_bert():\n    return load_model(\"original\")\n\n\ndef toxic_albert():\n    return load_model(\"original-small\")\n\n\ndef unbiased_toxic_roberta():\n    return load_model(\"unbiased\")\n\n\ndef unbiased_albert():\n    return load_model(\"unbiased-small\")\n\n\ndef multilingual_toxic_xlm_r():\n    return load_model(\"multilingual\")", "Constants and Shorthand Definition"]
]

code_short = [
    ["from typing import Optional, List\n\nimport numpy as np\nimport torch\nimport wandb\nimport copy\n\nfrom .model import Model\nfrom .data_classes import PruningConfig, RunDataHistory, \\\n                          RunDataItem, ActivationOverview\nfrom .eval import evaluate_all\nfrom .scoring import score_indices_by, score_indices\nfrom .activations import get_midlayer_activations, get_top_frac, \\\n    choose_attn_heads_by, save_timestamped_tensor_dict\nfrom .texts import prepare", "Import Statements"],
    ["def prune_and_evaluate(\n        opt: Model,\n        pruning_config: PruningConfig,\n        focus_out: Optional[dict] = None,\n        cripple_out: Optional[dict] = None,\n        iteration: Optional[int] = None,\n    ):\n    \"\"\"\n    Prune and evaluate the model\n\n    Args:\n        opt (Model): model to prune and evaluate\n        pruning_config (PruningConfig): config for pruning\n        focus_out (dict): output of get_midlayer_activations for focus dataset\n        cripple_out (dict): output of get_midlayer_activations for cripple dataset\n        iteration (int): iteration number for when activations are not recalculated\n\n    Returns:\n        output (RunDataItem): Eval data to add to RunDataHistory.\n    \"\"\"", "Function Definition and Doc string"],
    ["c = copy.deepcopy(pruning_config)\n\n    # Find out what we are doing\n    do_ff   = pruning_config.ff_frac > 0\n    do_attn = pruning_config.attn_frac > 0\n    if not do_ff and not do_attn:\n        raise ValueError(\"Must prune at least one of FF or Attention\")\n    if do_attn and pruning_config.attn_mode not in [\"pre-out\", \"value\"]:\n        raise NotImplementedError(\"attn_mode must be 'pre-out' or 'value'\")\n\n    # Get midlayer activations of FF and ATTN\n    if pruning_config.recalculate_activations:\n        focus_out   = get_midlayer_activations( opt, pruning_config.focus,\n            pruning_config.collection_sample_size, pruning_config.attn_mode )\n        cripple_out = get_midlayer_activations( opt, pruning_config.cripple,\n            pruning_config.collection_sample_size, pruning_config.attn_mode )\n\n    # Otherwise, import activation data, and adjust the \"pruning fraction\"\n    else:\n        c[\"ff_frac\"]   = min( 1.0, c[\"ff_frac\"]*(iteration+1) )\n        c[\"attn_frac\"] = min( 1.0, c[\"attn_frac\"]*(iteration+1) )\n        assert not (focus_out is None or cripple_out is None or iteration is None), \\\n            \"Must provide focus_out and cripple_out if not recalculate_activations\"\n\n    # Prune the model using the activation data\n    data = score_and_prune(opt, focus_out, cripple_out, c)\n\n    # Evaluate the model\n    with torch.no_grad():\n        eval_out = evaluate_all(opt, c.eval_sample_size, c.datasets,\n                                dataset_tokens_to_skip=c.collection_sample_size)\n        data.update(eval_out)\n\n    return data", "Function Logic"]
]
